---
title: "Fast Inference for Common-Factor Stochastic Volatility Models"
author: |
  | Martin Lysy
  | University of Waterloo
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{svcommon}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<!-- latex macros -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      TeX: {
	  Macros: {
	      bm: ["\\boldsymbol{#1}",1],
	      tx: ["\\textrm{#1}",1],
	      rv: ["#2_{#1},\\ldots,#2_{#3}",3,"1"],
	      iid: ["\\overset{\\;\\tx{iid}\\;}{\\sim}"],
	      ind: ["\\overset{\\:\\tx{ind}\\:}{\\sim}"],
	      var: ["\\operatorname{var}"],
	      cov: ["\\operatorname{cov}"],
	      cor: ["\\operatorname{cor}"],
	      N: ["\\mathcal{N}"],
	      ud: ["\\mathop{}\\!\\mathrm{d}"],
	      der: ["\\frac{\\ud^{#1}}{\\ud{#2}^{#1}}", 2, ""],
	      del: ["\\frac{\\partial^{#1}}{\\partial{#2}^{#1}}", 2, ""],
	      fder: ["\\frac{\\ud^{#1}#3}{\\ud{#2}^{#1}}", 3, ""],
	      fdel: ["\\frac{\\partial^{#1}#3}{\\partial{#2}^{#1}}", 3, ""],
	      hess: ["\\frac{\\partial^2}{\\partial{#1}\\partial{#1}'}", 1],
	      fhess: ["\\frac{\\partial^2#2}{\\partial{#1}\\partial{#1}'}", 2],
	      ww: ["{\\bm{w}}"],
	      xx: ["{\\bm{x}}"],
	      yy: ["{\\bm{y}}"],
	      zz: ["{\\bm{z}}"],
		  VV: ["{\\bm{V}}"],
	      XX: ["{\\bm{X}}"],
	      YY: ["{\\bm{Y}}"],
	      ZZ: ["{\\bm{Z}}"],
	      aal: ["{\\bm{\\alpha}}"],
	      bbe: ["{\\bm{\\beta}}"],
	      gga: ["{\\bm{\\gamma}}"],
	      eet: ["{\\bm{\\eta}}"],
	      lla: ["{\\bm{\\lambda}}"],
	      mmu: ["{\\bm{\\mu}}"],
	      pph: ["{\\bm{\\phi}}"],
	      pps: ["{\\bm{\\psi}}"],
	      rrh: ["{\\bm{\\rho}}"],
	      ssi: ["{\\bm{\\sigma}}"],
	      tta: ["{\\bm{\\tau}}"],
	      tth: ["{\\bm{\\theta}}"],
	      GGa: ["{\\bm{\\Gamma}}"],
	      SSi: ["{\\bm{\\Sigma}}"],
	      TTh: ["{\\bm{\\Theta}}"],
		  elL: ["\\ell_{\\mathrm{Lap}}"]
	  }
      }
  });
</script>


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  cache = TRUE
)
```

# The Common-Factor Multivariate Stochastic Volatility Model

Let $X_{it}$ denote the log price of asset $i$ at time $t$ and $V_{it}$ denote the corresponding volatility on the standard deviation scale.  The common-factor multivariate stochastic volatility (mSV) model proposed by Fang et al (2020) is marginally written as
$$
\begin{aligned}
\ud \log V_{it} & = -\gamma_i (\log V_{it} - \mu_i) \ud t + \sigma_i \ud B_{it}^V \\
\ud X_{it} & = (\alpha_i - \tfrac 1 2 V_{it}^2) \ud t + V_{it} \left(\rho_i \ud B_{it}^V + \sqrt{1 - \rho_i^2} \ud B_{it}^Z\right).
\end{aligned}
$$
The correlation between assets and volatilities comes from factor models for both the assets and the volatilities, namely
$$
\begin{aligned}
\ud B_{it}^V & = \tau_i \ud B_{\star t}^V + \sqrt{1 - \tau_i^2} \ud B_{it}^\epsilon \\
\ud B_{it}^Z & = \omega_i \ud B_{\star t}^Z + \sqrt{1 - \omega_i^2} \ud B_{it}^\eta.
\end{aligned}
$$
In Fang et al (2020) it is suggested to estimate the volatility common innovation factor $B_{\star t}^{V}$ via an observable proxy, for example the VIX.  That is, if $V_{\star t}$ is an observable proxy for the common volatility factor, then we use it to estimate $B_{\star t}^V$ via
$$
\ud \log V_{\star t} = -\gamma_{\star} (\log V_{\star t} - \mu_{\star}) \ud t + \sigma_{\star} \ud B_{\star t}^V.
$$
Here we propose to do something similar for the asset common innovation factor $B_{\star t}^Z$.  That is, let $(X_{0t}, V_{0t})$ be a univariate stochastic volatility model for an observable proxy for the common asset factor (for example, SPX).  Then we give it a similar marginal model to the above:
$$
\begin{aligned}
\ud \log V_{0t} & = -\gamma_0 (\log V_{0t} - \mu_0) \ud t + \sigma_0 \left(\tau_0 \ud B_{0t}^V + \sqrt{1 - \tau_0^2} \right)\\
\ud X_{0t} & = (\alpha_0 - \tfrac 1 2 V_{0t}^2) \ud t + V_{0t} \left(\rho_0 \ud B_{0 t}^Z + \sqrt{1 - \rho_0^2} \ud B_{0i}^\eta \right),
\end{aligned}
$$
where $\ud B_{0t}^V = \tau_0 \ud B_{\star t}^V + \sqrt{1 - \tau_0^2} \ud B_{0t}^\epsilon$.  The asset common factor is estimated from the proxy by equating $B_{\star t}^Z = B_{0t}^Z$.

# Parameter Estimation

```{r load_data, include = FALSE, message = FALSE}
library(svcommon)
dim(snp500) # automatically loaded with svcommon
snp500[1:6, ncol(snp500)-8 + 1:8]
```

**svcommon** uses the Laplace approximation with automatic differentiation provided by the **TMB** package to efficiently marginalize over the latent volatilities $\VV$ in order to calculate $\elL(\tth \mid \XX, \VV_0) \approx \log p(\XX, \VV_0 \mid \tth)$ and its gradient with respect to the model parameters $\tth$.  It then uses a block coordinate descent algorithm with good initial values to very quickly converge to the approximate MLE $\hat \tth = \operatorname{arg\,max}_{\tth} \elL(\XX, \VV_0 \mid \tth)$, about two orders of magnitude faster than exact inference methods.  The procedure is illustrated with a dataset consisting of `r nrow(snp500)` daily closing prices of `r ncol(snp500)-2` constituents of the S&P500, the index value itself (GSPC), and its volatility index (VIX).

```{r ref.label = "load_data"}
```

## Initialization

Initial guesses for the parameters of the common-factor stochastic volatility (SVC) model are obtain from marginal fits of the exponential Ornstein-Uhlenbeck (EOU) model to each asset and to GSPC.  As we shall see, the marginal fit are extremely fast and stable, even with parameters arbitrarily initialized to zero.

```{r init_opt}
# problem dimensions
nobs <- 250 # number of days
nasset <- 5 # number of assets, excluding GSPC

# format the data
dt <- 1/252
Xt <- as.matrix(cbind(GSPC = snp500[1:nobs, "GSPC"],
                      snp500[1:nobs, 1+1:nasset]))
Xt <- log(Xt)
log_VPt <- log(as.numeric(snp500[1:nobs, "VIX"]))

# initialize latent variables with rolling window standard deviations
log_Vt <- log(apply(Xt, 2, sv_init, dt = dt, block_size = 10))
# initialize parameters with default values
alpha <- rep(0, nasset+1)
log_gamma <- rep(0, nasset+2)
mu <- rep(0, nasset+2)
log_sigma <- rep(0, nasset+2)
logit_rho <- rep(0, nasset+1)
logit_tau <- rep(0, nasset+1)
logit_omega <- rep(0, nasset)

# parameter and latent variable list for convenient updating
curr_par <- list(log_Vt = log_Vt,
                 alpha = alpha,
                 log_gamma = log_gamma,
                 mu = mu,
                 log_sigma = log_sigma,
                 logit_rho = logit_rho,
                 logit_tau = logit_tau,
                 logit_omega = logit_omega)

# initialize parameters of each individual asset
# TODO: include VIX (though this probably won't add much)
for(iasset in 0:nasset) {
  message("asset = ", iasset)
  # construct model object
  eou_ad <- eou_MakeADFun(Xt = Xt[,iasset+1], dt = dt,
                          alpha = curr_par$alpha[iasset+1],
                          log_Vt = curr_par$log_Vt[,iasset+1],
                          log_gamma = curr_par$log_gamma[iasset+2],
                          mu = curr_par$mu[iasset+2],
                          log_sigma = curr_par$log_sigma[iasset+2],
                          logit_rho = curr_par$logit_rho[iasset+1])
  # optimize with quasi-newton method
  tm <- system.time({
    opt <- optim(par = eou_ad$par,
                 fn = eou_ad$fn,
                 gr = eou_ad$gr,
                 method = "BFGS", control = list(trace = 1))
  })
  message("Time: ", round(tm[3], 2), " seconds")
  # update parameters
  curr_par <- svc_update(eou_ad, old_par = curr_par, iasset = iasset)
}

```

## Blockwise Coordinate Descent

The following algorithm updates the parameters for each asset conditioned on the values of all the others.  Here, `nepoch` denotes the number of cycles through all assets.  For this dataset it appears that after `nepoch = 3` the parameter values are changing very little.

```{r block_coord}
nepoch <- 3

for(iepoch in 1:nepoch) {
  message("epoch = ", iepoch)
  for(iasset in -1:nasset) {
    message("asset = ", iasset)
    svc_ad <- svc_MakeADFun(Xt = Xt, log_VPt = log_VPt, dt = dt,
                            par_list = curr_par,
                            iasset = iasset)
    tm <- system.time({
      opt <- optim(par = svc_ad$par,
                   fn = svc_ad$fn,
                   gr = svc_ad$gr,
                   method = "BFGS", control = list(trace = 1))
    })
    message("Time: ", round(tm[3], 2), " seconds")
    curr_par <- svc_update(svc_ad, old_par = curr_par, iasset = iasset)
  }
}
```

## Final Touches

Let's take a look at the parameter estimates.

```{r}
# make all parameters non-fixed
svc_ad <- svc_MakeADFun(Xt = Xt, log_VPt = log_VPt, dt = dt,
                        par_list = curr_par,
                        iasset = "all")
sdreport(svc_ad)
```

We can see that a couple of the correlation values are extremely large, leading to large loss of numerical accuracy in the hessian calculation.  So let's try re-optimizing over the affected assets with the corresponding correlation set to zero.  For good measure, we'll also finish with a joint optimization over all parameters.  This should be comparatively fast now that the optimizer has good starting values.

```{r}
# re-initialized bad correlations
curr_par$logit_tau[2] <- 0
curr_par$logit_omega[5] <- 0

# rerun the affected block optimizations
bad_assets <- c(1, 5) # note the indexing
for(iasset in bad_assets) {
  message("asset = ", iasset)
  svc_ad <- svc_MakeADFun(Xt = Xt, log_VPt = log_VPt, dt = dt,
                          par_list = curr_par,
                          iasset = iasset)
  tm <- system.time({
    opt <- optim(par = svc_ad$par,
                 fn = svc_ad$fn,
                 gr = svc_ad$gr,
                 method = "BFGS", control = list(trace = 1))
  })
  message("Time: ", round(tm[3], 2), " seconds")
  curr_par <- svc_update(svc_ad, old_par = curr_par, iasset = iasset)
}

# global parameter optimization
iasset <- "all"
svc_ad <- svc_MakeADFun(Xt = Xt, log_VPt = log_VPt, dt = dt,
                        par_list = curr_par,
                        iasset = iasset)
tm <- system.time({
  opt <- optim(par = svc_ad$par,
               fn = svc_ad$fn,
               gr = svc_ad$gr,
               method = "BFGS", control = list(trace = 1))
})
curr_par <- svc_update(svc_ad, old_par = curr_par, iasset = iasset)
```

Now let's check the fitted results again:

```{r}
svc_rep <- sdreport(svc_ad)
svc_rep
```

Some of the estimates are quite poor, but with only ``nobs = `r nobs`` observations it's very difficult to estimate the correlation between the latent variables and observed quantities.  A better solution is perhaps to put a prior on the correlations keeping them away from senseless values.  For illustration purposes we'll stop here and store the MLE and its variance estimator.

```{r}
theta_mle <- svc_rep$par.fixed
theta_var <- svc_rep$cov.fixed
```
